{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:14pt;text-align:center;\">\n",
    "Pretraining network on pascal VOC.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN not available)\n",
      "/Library/Python/2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import pickle as pk\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "\n",
    "# image processing\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import Pool2DLayer, Conv2DLayer, dropout, \\\n",
    "    DenseLayer, InputLayer, get_output, get_all_params\n",
    "    \n",
    "import bnr_ml.objectdetect.yolo as yolo\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/usr/local/python/bnr_ml/data/PascalVOC/annotations.txt', 'rb') as f:\n",
    "    annotations = pk.load(f)['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_proper_labels(annotations):\n",
    "    for im in annotations:\n",
    "        for obj in im:\n",
    "            if 'car' in obj['label'].lower():\n",
    "                obj['label'] = 'car'\n",
    "            elif 'bicycle' in obj['label'].lower():\n",
    "                obj['label'] = 'bicycle'\n",
    "            elif 'person' in obj['label'].lower():\n",
    "                obj['label'] = 'person'\n",
    "            elif 'bike' in obj['label'].lower():\n",
    "                obj['label'] = 'bike'\n",
    "            else:\n",
    "                print obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_label_counts(annotations):\n",
    "    counts = np.zeros((4,))\n",
    "    for im in annotations:\n",
    "        for obj in im:\n",
    "            if obj['label'] == 'car':\n",
    "                counts[0] += 1\n",
    "            elif obj['label'] == 'bicycle':\n",
    "                counts[1] += 1\n",
    "            elif obj['label'] == 'bike':\n",
    "                counts[2] += 1\n",
    "            else:\n",
    "                counts[3] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_proper_labels(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = np.asarray(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = get_label_counts(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHyCAYAAAAZYFMeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgAAdP4vc954zL0k1CcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118841c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Distribution of labels', fontsize=20)\n",
    "plt.bar(np.arange(counts.size), counts, color='red', alpha=.4)\n",
    "plt.xticks(np.arange(counts.size) + .5, ['car', 'bicycle', 'bike', 'person'], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1991)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Split the annotations for training and testing, the reason I split by image and not individual object is so that when testing the performance, the network will never have seen any part of the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('indices.pkl', 'rb') as f:\n",
    "    indices = pk.load(f)\n",
    "    train_idx = indices['train_index']\n",
    "    test_idx = indices['test_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_annotations = annotations[train_idx]\n",
    "test_annotations = annotations[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Box(object):\n",
    "    def __init__(self, xi,yi,xf,yf):\n",
    "        self.xi = xi\n",
    "        self.yi = yi\n",
    "        self.xf = xf\n",
    "        self.yf = yf\n",
    "    def iou(self, box):\n",
    "        isec = self.intersection(box)\n",
    "        union = self.size() + box.size() - isec.size()\n",
    "        return isec.size() / union\n",
    "    def intersection(self, box):\n",
    "        new_xi = max(self.xi, box.xi)\n",
    "        new_yi = max(self.yi, box.yi)\n",
    "        new_xf = min(self.xf, box.xf)\n",
    "        new_yf = min(self.yf, box.yf)\n",
    "        if new_xi > new_xf or new_yi > new_yf:\n",
    "            new_xi, new_yi, new_xf, new_yf = 0., 0., 0., 0.\n",
    "        return Box(new_xi, new_yi, new_xf, new_yf)\n",
    "    def size(self):\n",
    "        return (self.xf - self.xi) * (self.yf - self.yi)\n",
    "    def width(self):\n",
    "        return (self.xf - self.xi)\n",
    "    def height(self):\n",
    "        return (self.yf - self.yi)\n",
    "    def copy(self):\n",
    "        return Box(self.xi, self.yi, self.xf, self.yf)\n",
    "    def subimage(self, im):\n",
    "        xi = max(0, self.xi)\n",
    "        yi = max(0, self.yi)\n",
    "        xf = min(im.shape[1], self.xf)\n",
    "        yf = min(im.shape[0], self.yf)\n",
    "        return im[yi:yf, xi:xf]\n",
    "    def round(self):\n",
    "        self.xi, self.yi, self.xf, self.yf = round(self.xi), round(self.yi), round(self.xf), round(self.yf)\n",
    "    def __str__(self):\n",
    "        return '(' + str(self.xi) + ',' + str(self.yi) + ') (' + str(self.xf) + ',' + str(self.yf) + ')'\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    @staticmethod\n",
    "    def gen_randombox(iou, box, eps=.5):\n",
    "        angle = 2 * np.pi * np.random.rand()\n",
    "        delx, dely = eps*np.cos(angle), eps*np.sin(angle)\n",
    "        new_box = box.copy()\n",
    "        while new_box.iou(box) > iou:\n",
    "            new_box.xi += delx\n",
    "            new_box.yi += dely\n",
    "            new_box.xf += delx\n",
    "            new_box.yf += dely\n",
    "        return new_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_data(annotations, size=(200,200), batch_size=100):\n",
    "    '''\n",
    "    augment: how many times do you want the data to be replicated\n",
    "    '''\n",
    "    def get_objects(annotations):\n",
    "        objs = []\n",
    "        for im in annotations:\n",
    "            objs.extend([deepcopy(obj) for obj in im])\n",
    "        return np.asarray(objs)\n",
    "    def get_num_from_label(label):\n",
    "        if label == 'car':\n",
    "            return 0\n",
    "        elif label == 'bicycle':\n",
    "            return 1\n",
    "        elif label == 'bike':\n",
    "            return 2\n",
    "        elif label == 'person':\n",
    "            return 3\n",
    "        elif label == 'noobj':\n",
    "            return 4\n",
    "        else:\n",
    "            pass\n",
    "#             print('This shouldn\\'t happen')\n",
    "    def subsample_objs(objs, obj_idx, size):\n",
    "        idx = obj_idx[np.random.random_integers(0,obj_idx.size-1, size=(size,))]\n",
    "        copy_obj = []\n",
    "        for obj in objs[idx]:\n",
    "            copy_obj.append(deepcopy(obj))\n",
    "        return np.asarray(copy_obj)\n",
    "    def set_label_to_noobj(objs, obj_idx):\n",
    "        N = np.int_(np.float_(obj_idx.size) / 5)\n",
    "        idx = np.arange(obj_idx.size)\n",
    "        np.random.shuffle(idx)\n",
    "        for obj in objs[obj_idx[idx[:N]]]:\n",
    "            obj['label']  = 'noobj'\n",
    "        return objs\n",
    "    \n",
    "    # return flat list of objects\n",
    "    objs = get_objects(annotations)\n",
    "    \n",
    "    # get number from label\n",
    "    labels = np.asarray([get_num_from_label(obj['label']) for obj in objs])\n",
    "    \n",
    "    idx = np.arange(labels.size)\n",
    "    idx_car = idx[labels==0]\n",
    "    idx_bicycle = idx[labels==1]\n",
    "    idx_bike = idx[labels==2]\n",
    "    idx_person = idx[labels==3]\n",
    "        \n",
    "    max_labels = np.max([idx_car.size, idx_bicycle.size, idx_bike.size, idx_person.size])\n",
    "    \n",
    "    # get subsamples to get equal number of classes\n",
    "    new_car = subsample_objs(objs, idx_car, max_labels - idx_car.size)\n",
    "    new_bicycle = subsample_objs(objs, idx_bicycle, max_labels - idx_bicycle.size)\n",
    "    new_bike = subsample_objs(objs, idx_bike, max_labels - idx_bike.size)\n",
    "    new_person = subsample_objs(objs, idx_person, max_labels - idx_person.size)\n",
    "    \n",
    "    # add new samples\n",
    "    objs = np.concatenate((objs, new_car, new_bicycle, new_bike, new_person))\n",
    "    \n",
    "    np.random.shuffle(objs)\n",
    "    \n",
    "    cnt = 0\n",
    "    while cnt < objs.size:\n",
    "        Xbatch = np.zeros((batch_size, 3) + size)\n",
    "        ybatch = np.zeros((batch_size, 4 + 4))\n",
    "        batch_cnt = 0\n",
    "        for j in range(batch_size):\n",
    "            if cnt < objs.size:\n",
    "                obj = objs[cnt]\n",
    "                im = imread(obj['image'])\n",
    "                im = im.astype(theano.config.floatX) / 255\n",
    "                xscale, yscale = np.float_(size[1]) / im.shape[1], np.float_(size[0]) / im.shape[0]\n",
    "#                 pdb.set_trace()\n",
    "                coord = np.asarray(obj['p1'] + obj['p2']).astype(theano.config.floatX)\n",
    "                coord[[0,2]] *= (xscale / 200)\n",
    "                coord[[1,3]] *= (yscale / 200)\n",
    "                coord[2:] = coord[2:] - coord[:2]\n",
    "                if im.shape.__len__() == 2:\n",
    "                    im = im.reshape(im.shape + (1,))\n",
    "                    im = np.concatenate((im, im, im), axis=2)\n",
    "                elif im.shape[2] == 4:\n",
    "                    im = im[:,:,:3]\n",
    "                if not (im.shape[0] == 0 or im.shape[1] == 0):\n",
    "                    im = resize(im, size).swapaxes(2,1).swapaxes(1,0)\n",
    "                    Xbatch[batch_cnt] = im\n",
    "                    ybatch[batch_cnt, :4] =  coord\n",
    "                    ybatch[batch_cnt, 4 + get_num_from_label(obj['label'])] += 1\n",
    "                    batch_cnt += 1\n",
    "            cnt += 1\n",
    "        if batch_cnt < batch_size - 1:\n",
    "            Xbatch, ybatch = Xbatch[:batch_cnt], ybatch[:batch_cnt]\n",
    "        yield Xbatch.astype(theano.config.floatX), ybatch.astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now we define the net for recognition.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = {}\n",
    "net['input'] = InputLayer((None,3,200,200))\n",
    "net['conv1'] = Conv2DLayer(net['input'], 16, (3,3))\n",
    "net['conv2'] = Conv2DLayer(net['conv1'], 16, (3,3))\n",
    "net['pool1'] = Pool2DLayer(net['conv2'], (2,2))\n",
    "net['conv3'] = Conv2DLayer(net['pool1'], 32, (3,3))\n",
    "net['conv4'] = Conv2DLayer(net['conv3'], 32, (3,3))\n",
    "net['pool2'] = Pool2DLayer(net['conv4'], (2,2))\n",
    "net['conv5'] = Conv2DLayer(net['pool2'], 64, (3,3))\n",
    "net['conv6'] = Conv2DLayer(net['conv5'], 64, (3,3))\n",
    "net['pool3'] = Pool2DLayer(net['conv6'], (2,2))\n",
    "net['conv7'] = Conv2DLayer(net['pool3'], 64, (3,3))\n",
    "net['conv8'] = Conv2DLayer(net['conv7'], 64, (3,3))\n",
    "net['pool4'] = Pool2DLayer(net['conv8'], (2,2))\n",
    "net['dense1'] = DenseLayer(dropout(net['pool4'], p=.8), 1000)\n",
    "net['dense2'] = DenseLayer(dropout(net['dense1'], p=.8), 1000)\n",
    "net['output'] = DenseLayer(dropout(net['dense2'], p=.5), 5, nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load pre-trained weights</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pretrained_weights.pkl', 'rb') as f:\n",
    "    weights = pk.load(f)\n",
    "    lasagne.layers.set_all_param_values(net['output'], weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Add extra layers to network for detection</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = (9,9)\n",
    "B = 2\n",
    "C = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net['dense1'] = DenseLayer(dropout(net['pool4'], p=.8), 2048)\n",
    "net['output'] = DenseLayer(dropout(net['dense1'], p=.8), (S[0] * S[1]) * (5 * B + C), nonlinearity=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bnr_ml.objectdetect.yolo' from '/usr/local/python/bnr_ml/objectdetect/yolo.py'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yl = yolo.YoloObjectDetector(net, (None, 3, 200, 200), C, S, B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = T.matrix('target')\n",
    "cost = yl._get_cost_optim(yl.output, target, S, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = theano.function([yl.input, target], cost, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_fn = theano.function([yl.input], yl.output, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(48559.640625, dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn(np.random.rand(100,3,200,200), np.random.rand(100,4 + C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = out_fn(100 * np.random.randn(10,3,200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0073986"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(tmp[:,[0,],:,:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cost...\n",
      "Creating cost variable took 0.3689 seconds\n",
      "Compiling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling functions took 83.3794 seconds\n",
      "Beginning training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [03:49<34:25, 229.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "------\n",
      "Train Loss: nan, Test Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss = yl.train(\n",
    "    generate_data(train_annotations),\n",
    "    generate_data(test_annotations),\n",
    "    lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_loss_total, test_loss_total = train_loss, test_loss\n",
    "train_loss_total = np.concatenate((train_loss_total, train_loss))\n",
    "test_loss_total = np.concatenate((test_loss_total, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(train_loss_total, 'b')\n",
    "epochs = np.arange(num_epochs)\n",
    "idx = epochs % test_every == 0\n",
    "plt.plot(epochs[idx], test_loss_total[idx], 'r')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
