{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:14pt;text-align:center;\">\n",
    "Train YOLO network on pascal VOC.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colingaudreau/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using gpu device 0: GeForce GTX 960 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN not available)\n",
      "/Library/Python/2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import pickle as pk\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import simplejson\n",
    "\n",
    "# image processing\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import Pool2DLayer, Conv2DLayer, dropout, \\\n",
    "    DenseLayer, InputLayer, get_output, get_all_params\n",
    "from lasagne import nonlinearities\n",
    "from lasagne import layers\n",
    "    \n",
    "import bnr_ml.objectdetect.yolo as yolo\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/usr/local/python/bnr_ml/data/PascalVOC/annotations.json', 'r') as f:\n",
    "    annotations = simplejson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_counts(annotations):\n",
    "    counts = np.zeros((4,))\n",
    "    for a in annotations:\n",
    "        for obj in a['annotations']:\n",
    "            if obj['label'] == 'car':\n",
    "                counts[0] += 1\n",
    "            elif obj['label'] == 'bicycle':\n",
    "                counts[1] += 1\n",
    "            elif obj['label'] == 'bike':\n",
    "                counts[2] += 1\n",
    "            else:\n",
    "                counts[3] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_labels(annotations):\n",
    "    for a in annotations:\n",
    "        a['image'] = '/usr/local/python/bnr_ml/data/PascalVOC/' + a['image']\n",
    "        new_objs = []\n",
    "        for obj in a['annotations']:\n",
    "            lab = obj['label'].lower()\n",
    "            if 'car' in lab:\n",
    "                lab = 'car'\n",
    "            elif 'person' in lab:\n",
    "                lab = 'person'\n",
    "            elif 'bike' in lab:\n",
    "                lab = 'bike'\n",
    "            elif 'bicycle' in lab:\n",
    "                lab = 'bicycle'\n",
    "            else:\n",
    "                lab = None\n",
    "                \n",
    "            if lab != None:\n",
    "                obj['label'] = lab\n",
    "                new_objs.append(obj)\n",
    "        a['annotations'] = new_objs\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = np.asarray(fix_labels(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = get_label_counts(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHyCAYAAAAZYFMeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMun4pxgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1187e1050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Distribution of labels', fontsize=20)\n",
    "plt.bar(np.arange(counts.size), counts, color='red', alpha=.4)\n",
    "plt.xticks(np.arange(counts.size) + .5, ['car', 'bicycle', 'bike', 'person'], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1991)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Split the annotations for training and testing, the reason I split by image and not individual object is so that when testing the performance, the network will never have seen any part of the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('indices.pkl', 'rb') as f:\n",
    "    indices = pk.load(f)\n",
    "    train_idx = indices['train_index']\n",
    "    test_idx = indices['test_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_annotations = annotations[train_idx]\n",
    "test_annotations = annotations[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_data_2(annotations, C, max_objs=15, size=(200,200), batch_size=100):\n",
    "    def reformat_image(im, new_size):\n",
    "        if im.shape.__len__() == 2:\n",
    "            im = np.repeat(im.reshape(im.shape + (1,)), 3, axis=2)\n",
    "        elif im.shape[2] > 3:\n",
    "            im = im[:,:,:3]\n",
    "        if im.shape[0] == 0 or im.shape[2] == 0:\n",
    "            return None\n",
    "        return resize(im, new_size).swapaxes(2,1).swapaxes(1,0)\n",
    "    def transform_coord(coord, old_size, new_size):\n",
    "        coord[[0,2]] = np.float_(coord[[0,2]]) / old_size[1]\n",
    "        coord[[1,3]] = np.float_(coord[[1,3]]) / old_size[0]\n",
    "        \n",
    "        if coord[2] >= coord[0]:\n",
    "            coord[2] -= coord[0]\n",
    "        else:\n",
    "            coord[2] = coord[0] - coord[2]\n",
    "        if coord[3] >= coord[1]:\n",
    "            coord[3] -= coord[1]\n",
    "        else:\n",
    "            coord[3] = coord[1] - coord[3]\n",
    "        return coord\n",
    "    def get_num_from_label(label):\n",
    "        if label == 'car':\n",
    "            return 0\n",
    "        elif label == 'bicycle':\n",
    "            return 1\n",
    "        elif label == 'bike':\n",
    "            return 2\n",
    "        elif label == 'person':\n",
    "            return 3\n",
    "        elif label == 'noobj':\n",
    "            return 4\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "#     annotations = np.asarray([[deepcopy(obj) for obj in objs] for objs in annotations]) # deep copy annotations\n",
    "\n",
    "    fake_truth = np.concatenate((np.asarray([-10.,-10.,.01,.01]), np.zeros((C,))))\n",
    "    \n",
    "    np.random.shuffle(annotations)\n",
    "    \n",
    "    for i in range(0,annotations.shape[0], batch_size):\n",
    "        Xbatch = np.zeros((batch_size,3) + size)\n",
    "        ybatch = np.zeros((batch_size, (4 + C) * max_objs))\n",
    "        \n",
    "        for j in range(min(batch_size, annotations.shape[0] - i)):\n",
    "            annotation = annotations[i+j]\n",
    "            objs = annotation['annotations']\n",
    "            im = imread(annotation['image'])\n",
    "            old_size = np.float_(annotation['size'])\n",
    "            \n",
    "            Xbatch[j] = reformat_image(im, size)\n",
    "            \n",
    "            for k in range(max_objs):\n",
    "                if k < objs.__len__():\n",
    "                    obj = objs[k]\n",
    "                    coord = np.asarray([\n",
    "                            obj['x'],\n",
    "                            obj['y'],\n",
    "                            obj['w'],\n",
    "                            obj['h']\n",
    "                        ], dtype=theano.config.floatX)\n",
    "                    coord = transform_coord(coord, old_size, size)\n",
    "                    ybatch[j,k*(4 + C):k*(4 + C) + 4] = coord\n",
    "                    ybatch[j,k*(4 + C)+4 + get_num_from_label(obj['label'])] += 1\n",
    "                else:\n",
    "                    ybatch[j,k*(4 + C):(k + 1)*(4 + C)] = fake_truth\n",
    "            \n",
    "        yield Xbatch[:j+1].astype(theano.config.floatX), ybatch[:j+1].astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data_3(annotations, C, max_objs=15, size=(200,200), batch_size=100, augment=10):\n",
    "    def reformat_image(im, new_size):\n",
    "        if im.shape.__len__() == 2:\n",
    "            im = np.repeat(im.reshape(im.shape + (1,)), 3, axis=2)\n",
    "        elif im.shape[2] > 3:\n",
    "            im = im[:,:,:3]\n",
    "        if im.shape[0] == 0 or im.shape[2] == 0:\n",
    "            return None\n",
    "        return resize(im, new_size)\n",
    "    def transform_coord(coord, old_size, new_size):\n",
    "        coord[[0,2]] *= 1. / old_size[1]\n",
    "        coord[[1,3]] *= 1. / old_size[0]\n",
    "        \n",
    "        if coord[2] >= coord[0]:\n",
    "            coord[2] -= coord[0]\n",
    "        else:\n",
    "            coord[2] = coord[0] - coord[2]\n",
    "        if coord[3] >= coord[1]:\n",
    "            coord[3] -= coord[1]\n",
    "        else:\n",
    "            coord[3] = coord[1] - coord[3]\n",
    "        return coord\n",
    "    def get_num_from_label(label):\n",
    "        if label == 'car':\n",
    "            return 0\n",
    "        elif label == 'bicycle':\n",
    "            return 1\n",
    "        elif label == 'bike':\n",
    "            return 2\n",
    "        elif label == 'person':\n",
    "            return 3\n",
    "        elif label == 'noobj':\n",
    "            return 4\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    annotations = np.asarray([[deepcopy(obj) for obj in objs] for objs in annotations]) # deep copy annotations\n",
    "\n",
    "    fake_truth = np.concatenate((np.asarray([-10.,-10.,.01,.01]), np.zeros((C,))))\n",
    "    \n",
    "    np.random.shuffle(annotations)\n",
    "    \n",
    "    for num in range(augment):\n",
    "        for i in range(0,annotations.size, batch_size):\n",
    "            Xbatch = np.zeros((batch_size,3) + size)\n",
    "            ybatch = np.zeros((batch_size, (4 + C) * max_objs))\n",
    "\n",
    "            for j in range(min(batch_size, annotations.size - i)):\n",
    "                objs = annotations[i+j][annotations]\n",
    "                im = imread(annotations[i+j]['image'])\n",
    "                old_size = im.shape\n",
    "                \n",
    "                old_box = Box(0.,0.,1.,1.)\n",
    "                iterlap = .8\n",
    "                new_width = iterlap + (1. - iterlap) * np.random.rand()\n",
    "                new_height = iterlap +  (1. - iterlap) * np.random.rand()\n",
    "                new_xi = (1. - new_width) * np.random.rand()\n",
    "                new_yi = (1. - new_height) * np.random.rand()\n",
    "                new_box = Box(\n",
    "                    new_xi,\n",
    "                    new_yi,\n",
    "                    new_width + new_xi,\n",
    "                    new_height + new_yi\n",
    "                )\n",
    "                im = new_box.subimage(im)\n",
    "\n",
    "                im = reformat_image(im, size)\n",
    "                \n",
    "                im = rgb2hsv(im)\n",
    "                im[:,:,[0,2]] *= (1 + .1 * np.random.rand(1,1,2))\n",
    "                im = hsv2rgb(im)\n",
    "                \n",
    "                Xbatch[j] = im.swapaxes(2,1).swapaxes(1,0)\n",
    "\n",
    "                for k in range(max_objs):\n",
    "                    if k < objs.__len__():\n",
    "                        obj = objs[k]\n",
    "                        coord = np.asarray([\n",
    "                                obj['x'],\n",
    "                                obj['y'],\n",
    "                                obj['w'],\n",
    "                                obj['h']\n",
    "                            ])\n",
    "#                         coord = np.asarray(obj['p1'] + obj['p2']).astype(theano.config.floatX)\n",
    "                        coord = transform_coord(coord, old_size, size)\n",
    "                        \n",
    "                        obj_box = Box(coord[0], coord[1], coord[0] + coord[2], coord[1] + coord[3])\n",
    "                        \n",
    "                        if new_box.iou(obj_box) > 0.5:\n",
    "                            coord[0] -= new_box.xi\n",
    "                            coord[1] -= new_box.yi\n",
    "                            coord[[0,2]] /= (new_box.xf - new_box.xi)\n",
    "                            coord[[1,3]] /= (new_box.yf - new_box.yi)\n",
    "                            ybatch[j,k*(4 + C):k*(4 + C) + 4] = coord\n",
    "                            ybatch[j,k*(4 + C)+4 + get_num_from_label(obj['label'])] += 1\n",
    "                        else:\n",
    "                            ybatch[j,k*(4 + C):(k + 1)*(4 + C)] = fake_truth\n",
    "\n",
    "                    else:\n",
    "                        ybatch[j,k*(4 + C):(k + 1)*(4 + C)] = fake_truth\n",
    "\n",
    "            yield Xbatch[:j+1].astype(theano.config.floatX), ybatch[:j+1].astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_data(annotations, C, size=(200,200), batch_size=100):\n",
    "    '''\n",
    "    augment: how many times do you want the data to be replicated\n",
    "    '''\n",
    "    def get_objects(annotations):\n",
    "        objs = []\n",
    "        for im in annotations:\n",
    "            objs.extend([deepcopy(obj) for obj in im])\n",
    "        return np.asarray(objs)\n",
    "    def get_num_from_label(label):\n",
    "        if label == 'car':\n",
    "            return 0\n",
    "        elif label == 'bicycle':\n",
    "            return 1\n",
    "        elif label == 'bike':\n",
    "            return 2\n",
    "        elif label == 'person':\n",
    "            return 3\n",
    "        elif label == 'noobj':\n",
    "            return 4\n",
    "        else:\n",
    "            pass\n",
    "#             print('This shouldn\\'t happen')\n",
    "    def subsample_objs(objs, obj_idx, size):\n",
    "        idx = obj_idx[np.random.random_integers(0,obj_idx.size-1, size=(size,))]\n",
    "        copy_obj = []\n",
    "        for obj in objs[idx]:\n",
    "            copy_obj.append(deepcopy(obj))\n",
    "        return np.asarray(copy_obj)\n",
    "    def set_label_to_noobj(objs, obj_idx):\n",
    "        N = np.int_(np.float_(obj_idx.size) / 5)\n",
    "        idx = np.arange(obj_idx.size)\n",
    "        np.random.shuffle(idx)\n",
    "        for obj in objs[obj_idx[idx[:N]]]:\n",
    "            obj['label']  = 'noobj'\n",
    "        return objs\n",
    "    \n",
    "    # return flat list of objects\n",
    "    objs = get_objects(annotations)\n",
    "    \n",
    "    # get number from label\n",
    "    labels = np.asarray([get_num_from_label(obj['label']) for obj in objs])\n",
    "    \n",
    "    idx = np.arange(labels.size)\n",
    "    idx_car = idx[labels==0]\n",
    "    idx_bicycle = idx[labels==1]\n",
    "    idx_bike = idx[labels==2]\n",
    "    idx_person = idx[labels==3]\n",
    "        \n",
    "    max_labels = np.max([idx_car.size, idx_bicycle.size, idx_bike.size, idx_person.size])\n",
    "    \n",
    "    # get subsamples to get equal number of classes\n",
    "    new_car = subsample_objs(objs, idx_car, max_labels - idx_car.size)\n",
    "    new_bicycle = subsample_objs(objs, idx_bicycle, max_labels - idx_bicycle.size)\n",
    "    new_bike = subsample_objs(objs, idx_bike, max_labels - idx_bike.size)\n",
    "    new_person = subsample_objs(objs, idx_person, max_labels - idx_person.size)\n",
    "    \n",
    "    # add new samples\n",
    "    objs = np.concatenate((objs, new_car, new_bicycle, new_bike, new_person))\n",
    "    \n",
    "    np.random.shuffle(objs)\n",
    "    \n",
    "    cnt = 0\n",
    "    while cnt < objs.size:\n",
    "        Xbatch = np.zeros((batch_size, 3) + size)\n",
    "        ybatch = np.zeros((batch_size, 4 + C))\n",
    "        batch_cnt = 0\n",
    "        for j in range(batch_size):\n",
    "            if cnt < objs.size:\n",
    "                obj = objs[cnt]\n",
    "                im = imread(obj['image'])\n",
    "                im = im.astype(theano.config.floatX) / 255\n",
    "                xscale, yscale = np.float_(size[1]) / im.shape[1], np.float_(size[0]) / im.shape[0]\n",
    "#                 pdb.set_trace()\n",
    "                coord = np.asarray(obj['p1'] + obj['p2']).astype(theano.config.floatX)\n",
    "                coord[[0,2]] *= (xscale / 200)\n",
    "                coord[[1,3]] *= (yscale / 200)\n",
    "                if coord[2] >= coord[0]:\n",
    "                    coord[2] -= coord[0]\n",
    "                else:\n",
    "                    coord[2] = coord[0] - coord[2]\n",
    "                if coord[3] >= coord[1]:\n",
    "                    coord[3] -= coord[1]\n",
    "                else:\n",
    "                    coord[3] = coord[1] - coord[3]\n",
    "                    \n",
    "                if coord[2] < 0 or coord[3] < 0:\n",
    "                    print image\n",
    "                    \n",
    "                if im.shape.__len__() == 2:\n",
    "                    im = im.reshape(im.shape + (1,))\n",
    "                    im = np.concatenate((im, im, im), axis=2)\n",
    "                elif im.shape[2] == 4:\n",
    "                    im = im[:,:,:3]\n",
    "                if not (im.shape[0] == 0 or im.shape[1] == 0):\n",
    "                    im = resize(im, size).swapaxes(2,1).swapaxes(1,0)\n",
    "                    Xbatch[batch_cnt] = im\n",
    "                    ybatch[batch_cnt, :4] =  coord\n",
    "                    ybatch[batch_cnt, 4 + get_num_from_label(obj['label'])] += 1\n",
    "                    batch_cnt += 1\n",
    "            cnt += 1\n",
    "        if batch_cnt < batch_size - 1:\n",
    "            Xbatch, ybatch = Xbatch[:batch_cnt], ybatch[:batch_cnt]\n",
    "        yield Xbatch.astype(theano.config.floatX), ybatch.astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now we define the net for recognition.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = (6,6)\n",
    "B = 2\n",
    "C = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 10\n",
    "input_shape = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_net = False\n",
    "if test_net:\n",
    "    Xtest, ytest = [t for t in generate_data_2(train_annotations[:10], C, batch_size=batch_size)][0]\n",
    "    Xtest, ytest = theano.shared(Xtest), theano.shared(ytest)\n",
    "    input_var = Xtest\n",
    "else:\n",
    "    input_var=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = {}\n",
    "net['input'] = InputLayer((None, 3) + input_shape, input_var=input_var)\n",
    "net['conv1_1'] = Conv2DLayer(net['input'], 64, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv1_2'] = Conv2DLayer(net['conv1_1'], 64, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['pool1'] = Pool2DLayer(net['conv1_2'], 2)\n",
    "net['conv2_1'] = Conv2DLayer( net['pool1'], 128, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv2_2'] = Conv2DLayer(net['conv2_1'], 128, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['pool2'] = Pool2DLayer(net['conv2_2'], 2)\n",
    "net['conv3_1'] = Conv2DLayer(net['pool2'], 256, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv3_2'] = Conv2DLayer(net['conv3_1'], 256, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv3_3'] = Conv2DLayer(net['conv3_2'], 256, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['pool3'] = Pool2DLayer(net['conv3_3'], 2)\n",
    "net['conv4_1'] = Conv2DLayer(net['pool3'], 512, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv4_2'] = Conv2DLayer(net['conv4_1'], 512, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv4_3'] = Conv2DLayer(net['conv4_2'], 512, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['pool4'] = Pool2DLayer(net['conv4_3'], 2)\n",
    "net['conv5_1'] = Conv2DLayer(net['pool4'], 512, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv5_2'] = Conv2DLayer(net['conv5_1'], 512, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['conv5_3'] = Conv2DLayer(net['conv5_2'], 512, 3, pad=1, nonlinearity=nonlinearities.leaky_rectify)\n",
    "net['pool5'] = Pool2DLayer(net['conv5_3'], 2)\n",
    "net['fc6'] = DenseLayer(net['pool5'], num_units=2048, nonlinearity=None)\n",
    "net['fc6_dropout'] = dropout(net['fc6'], p=0.5)\n",
    "net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=2048, nonlinearity=None)\n",
    "net['fc7_dropout'] = dropout(net['fc7'], p=0.5)\n",
    "# net['fc8'] = DenseLayer(net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "# net['prob'] = NonlinearityLayer(net['fc8'], nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load pre-trained weights</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_pretrained = True\n",
    "if load_pretrained:\n",
    "    with open('/usr/local/python/bnr_ml/data/pretrained/vgg16.pkl', 'rb') as f:\n",
    "        weights = pk.load(f)['param values']\n",
    "        lasagne.layers.set_all_param_values(net['conv5_3'], weights[:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Add extra layers to network for detection</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net['fc6'] = DenseLayer(net['pool5'], 2048, nonlinearity=None)\n",
    "net['output'] = DenseLayer(dropout(net['fc6'], p=.5), (B * (C + 1) + 4) * (S[0] * S[1]), nonlinearity=None)\n",
    "# net['output'] = DenseLayer(dropout(net['dense1'], p=.0), (B * 5 + C) * S[0]*S[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_weights = False\n",
    "if load_weights:\n",
    "    with open('yolo_weights.pkl', 'rb') as f:\n",
    "        weights = pk.load(f)\n",
    "        lasagne.layers.set_all_param_values(net['output'], weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bnr_ml.objectdetect.yolo' from '/usr/local/python/bnr_ml/objectdetect/yolo.pyc'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    }
   ],
   "source": [
    "yl = yolo.YoloObjectDetector(net, (None, 3) + input_shape, C, S, B) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cost = yl._get_cost_optim_multi(yl.output, ytest, S, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cost...\n",
      "Creating cost variable took 0.7971 seconds\n",
      "Compiling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling functions took 35.3493 seconds\n",
      "Beginning training...\n",
      "298.571435547\n",
      "293.910522461\n",
      "292.271484375\n",
      "161.414953613\n",
      "156.87199707\n",
      "135.586523438\n",
      "226.473168945\n",
      "217.525878906\n",
      "88.7337280273\n",
      "147.927600098\n",
      "93.3462402344\n",
      "97.2674804687\n",
      "155.71105957\n",
      "70.4098388672\n",
      "121.776049805\n",
      "120.942883301\n",
      "106.157226562\n",
      "149.244152832\n",
      "122.735009766\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss = yl.train(\n",
    "    generate_data_2(train_annotations, C, size=input_shape, batch_size=batch_size),\n",
    "    generate_data_2(test_annotations, C, size=input_shape, batch_size=batch_size),\n",
    "    lr=1e-5,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('yolo_weights.pkl', 'wb') as f:\n",
    "    weights = lasagne.layers.get_all_param_values(net['output'])\n",
    "    pk.dump(weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loss_total, test_loss_total = train_loss, test_loss\n",
    "# train_loss_total = np.concatenate((train_loss_total, train_loss))\n",
    "# test_loss_total = np.concatenate((test_loss_total, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "idx = train_loss_total != 0\n",
    "plt.plot(train_loss_total[idx], 'b')\n",
    "plt.plot(test_loss_total[idx], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = generate_data_2(train_annotations[200:300], C, max_objs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdat = [t for t in gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest, ytest = testdat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_fn = theano.function([yl.input], yl.output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest_out = out_fn(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = int(np.random.rand() * Xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coords = yolo.YoloObjectDetector.nms(Xtest_out[N], S, B, C, thresh=.3, overlap=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = yolo.YoloObjectDetector.draw_coord(swap(Xtest[N]), coords, get_label_from_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.copy(Xtest_out[N])\n",
    "score = pred[[4,9]] * pred[-C:].max(keepdims=True)\n",
    "score = score.flatten()\n",
    "args = score.argsort()[::-1][:10]\n",
    "preds = []\n",
    "for i in range(args.size):\n",
    "    idx = np.unravel_index(args[i], pred[[4,9]].shape)\n",
    "    crd = pred[5*idx[0]:5*idx[0] + 4,idx[1], idx[2]]\n",
    "    tmp = crd[[2,3]]\n",
    "    tmp[tmp<1] = 0.5*tmp[tmp<1]**2\n",
    "    tmp[tmp>=1] = np.abs(tmp[tmp>=1]) - 0.5\n",
    "    crd[[2,3]] = tmp\n",
    "    crd = crd.tolist()\n",
    "    crd[0], crd[1] = crd[0] + np.float_(idx[2]) /S[1], crd[1] + np.float_(idx[1]) / S[0]\n",
    "    crd.append(score[args[i]])\n",
    "    preds.append(crd)\n",
    "preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nms(preds, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(draw_coord(swap(Xtest[N]), nms(preds, .3)[0], None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = np.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swap = lambda x: x.swapaxes(0,1).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = int(Xtest.shape[0] * np.random.rand())\n",
    "print N\n",
    "a, b = draw_best(swap(Xtest[N]), Xtest_out[N], num = 5, thresh=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(a)\n",
    "print b\n",
    "# print '%s with class score: %.3f, objectness: %.3f' % (get_label_from_num(c.argmax()), c.max(), b)\n",
    "# print c\n",
    "# print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = swap(Xtest[int(np.random.rand()*Xtest.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im2 = rgb2hsv(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im2[:,:,1:] *= (1. + .3 * np.random.rand(1,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(hsv2rgb(im2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im3 = hsv2rgb(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
